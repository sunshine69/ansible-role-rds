- name: Gather facts about the {{ role_type }} RDS Subnets in {{ env }}
  ec2_vpc_subnet_facts:
    region: "{{ region }}"
    profile: "{{ profile|default(omit) }}"
    filters:
      "tag:Environment": "{{ env }}"
      "tag:Application": "{{ role_type }}"
      "tag:Tier": rds
  register: rds_subnets

- debug:
    var: rds_subnets
    verbosity: 2

- name: Gather facts about the {{ role_type }} RDS Security Groups in {{ env }}
  ec2_group_facts:
    region: "{{ region }}"
    profile: "{{ profile|default(omit) }}"
    filters:
      "tag:Environment": "{{ env }}"
      "tag:Application": "{{ role_type }}"
      "tag:Tier": rds
      "tag:Engine" : "{{ rds_option_group.engine_name|default(rds_engine) }}"
      "tag:Public": "{{ rds_is_public|default('*')|string }}"
  register: rds_security_groups

- fail:
    msg: "Not found any security group xvt-{{ vpc_name }}-sg-{{ role_type }}-rds"
  when: not rds_security_groups.security_groups

- name: set the security group list fact
  set_fact:
    vpc_security_group_ids: "{{ rds_security_groups | json_query('security_groups[].group_id') }}"

- debug:
    msg: "List of rds_security_groups found {{ vpc_security_group_ids }}"
    verbosity: 2

# If existing subnet group having different vpc-id then the below will fail
# with message 'The new Subnets are not in the same Vpc as the existing subnet
# group'. Reason is aws does not allow to edit/change the vpcid.
# To fix, use the aws console and manually delete these rds subnet group and
# re-run ansible again.
- name: create the rds_subnet_group
  rds_subnet_group:
    region: "{{ region }}"
    profile: "{{ profile|default(omit) }}"
    name: "{{ rds_subnet_group.name }}"
    description: "{{ rds_subnet_group.description }}"
    subnets: "{{ rds_subnets.subnets | map(attribute='id') |list }}"
    state: present

- debug:
    var: rds_parameter_group
    verbosity: 2

- name: create the parameter_group
  rds_param_group:
    region: "{{ region }}"
    profile: "{{ profile|default(omit) }}"
    name: "{{ rds_parameter_group.name }}"
    description: "{{ rds_parameter_group.description }}"
    params: "{{ rds_parameter_group.params }}"
    engine: "{{ rds_parameter_groups_engine|default(rds_option_group.engine_name + rds_option_group.major_engine_version) }}"
    state: present
    immediate: "{{ rds_parameter_group.apply_immediately }}"
    tags:
      Environment: "{{ env }}"
      Tier: rds
      Application: "{{ role_type }}"
  register: rds_param_group

- debug:
    var: rds_option_group
    verbosity: 2

- name: create the option_group_name
  rds_option_group:
    region: "{{ region }}"
    profile: "{{ profile|default(omit) }}"
    option_group_name: "{{ rds_option_group.name }}"
    engine_name: "{{ rds_option_group.engine_name }}"
    major_engine_version: "{{ rds_option_group.major_engine_version }}"
    option_group_description: "{{ rds_option_group.description }}"
    apply_immediately: "{{ rds_option_group.apply_immediately }}"
    state: present

- debug:
    var: rds_db_instances
    verbosity: 2

- name: Create the {{ role_type }}-{{ db_instance_type }} RDS instance
  rds_instance:
    region: "{{ region }}"
    profile: "{{ profile|default(omit) }}"
    db_instance_identifier: "{{ item.db_instance_identifier }}"
    db_name: "{{ item.database|default(omit) }}"
    engine: "{{ item.engine }}"
    engine_version: "{{ rds_option_group.major_engine_version }}"
    db_instance_class: "{{ item.db_instance_class }}"
    master_username: "{{ item.master_user_name }}"
    master_user_password: "{{ item.master_user_password }}"
    size: "{{ item.allocated_storage }}"
    storage_type: "{{ item.storage_type }}"
    # It works but only if we do the whole rebuild of rds for all env to match
    # up the engine version. Commented out for now until we have a chance to
    # rebuild all from scratch to have consistent rds version in engine and
    # param group.
    db_parameter_group_name: "{{ rds_parameter_group.name  }}"
    option_group_name: "{{ rds_option_group.name }}"
    vpc_security_group_ids: "{{ vpc_security_group_ids }}"
    subnet: "{{ rds_subnet_group.name }}"
    tags: "{{ item.tags }}"
    multi_az: "{{ item.multi_az }}"
    wait: "{{ item.wait }}"
    wait_timeout: "{{ item.wait_timeout }}"
    force_password_update: "{{ rds_force_password_update|default('no') }}"
    license_model: "{{ item.license_model|default(omit) }}"
    backup_retention_period: "{{ item.backup_retention_period|default(omit) }}"
    preferred_backup_window: "{{ item.preferred_backup_window|default(omit) }}"
    preferred_maintenance_window: "{{ item.preferred_maintenance_window|default(omit) }}"
  with_items: "{{ rds_db_instances }}"
  register: master_rds_instance
  when: "db_instance_type  == 'master'"

- name: Set fact rds_internal_dns
  set_fact:
    rds_internal_dns: "{{ role_type }}-{{ db_instance_type }}.{{ env }}.{{ tld_name_internal }}"
  when: rds_internal_dns is not defined or not rds_internal_dns

- debug:
    var: rds_internal_dns
    verbosity: 2

- name: Create Route 53 internal rds master record entry for {{ role_type }}
  include_role:
    name: aws_route53
  vars:
    aws_route53_profile: "{{ profile|default(omit) }}"
    aws_route53:
      zone: "{{ tld_name_internal }}"
      record: "{{ rds_internal_dns }}"
      value: "{{ item.instance.endpoint.address }}"
      type: CNAME
      ttl: 300
      overwrite: yes
  with_items: "{{ master_rds_instance.results|default([]) }}"
